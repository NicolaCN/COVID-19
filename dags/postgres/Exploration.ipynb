{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Country       YR2019       YR2020  \\\n",
      "economy                                                             \n",
      "ZWE                            Zimbabwe   15354608.0   15669666.0   \n",
      "ZMB                              Zambia   18380477.0   18927715.0   \n",
      "YEM                         Yemen, Rep.   31546691.0   32284046.0   \n",
      "PSE                  West Bank and Gaza    4685306.0    4803269.0   \n",
      "VIR               Virgin Islands (U.S.)     106669.0     106290.0   \n",
      "...                                 ...          ...          ...   \n",
      "CEB      Central Europe and the Baltics  102398537.0  102180124.0   \n",
      "CSS              Caribbean small states    7424102.0    7444768.0   \n",
      "ARB                          Arab World  441467739.0  449228296.0   \n",
      "AFW          Africa Western and Central  454306063.0  466189102.0   \n",
      "AFE         Africa Eastern and Southern  667242986.0  685112979.0   \n",
      "\n",
      "              YR2021       YR2022       YR2023  \n",
      "economy                                         \n",
      "ZWE       15993524.0   16320537.0   16320537.0  \n",
      "ZMB       19473125.0   20017675.0   20017675.0  \n",
      "YEM       32981641.0   33696614.0   33696614.0  \n",
      "PSE        4922749.0    5043612.0    5043612.0  \n",
      "VIR         105870.0     105413.0     105413.0  \n",
      "...              ...          ...          ...  \n",
      "CEB      101410997.0  100648571.0  100648571.0  \n",
      "CSS        7481877.0    7505478.0    7505478.0  \n",
      "ARB      456520777.0  464684914.0  464684914.0  \n",
      "AFW      478185907.0  490330870.0  490330870.0  \n",
      "AFE      702977106.0  720839314.0  720839314.0  \n",
      "\n",
      "[266 rows x 6 columns]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "2022",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\super\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\super\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\super\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 2022",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\super\\Desktop\\DATA_ENGINEERING\\Project_git\\FODE-23-22\\dags\\postgres\\Exploration.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/super/Desktop/DATA_ENGINEERING/Project_git/FODE-23-22/dags/postgres/Exploration.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m data_reshaped \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmelt(data, id_vars\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mCountry\u001b[39m\u001b[39m'\u001b[39m], var_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mYear\u001b[39m\u001b[39m'\u001b[39m, value_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTotal Population\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/super/Desktop/DATA_ENGINEERING/Project_git/FODE-23-22/dags/postgres/Exploration.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m#Manually add the population for 2023 and set it equal to the population of 2022\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/super/Desktop/DATA_ENGINEERING/Project_git/FODE-23-22/dags/postgres/Exploration.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m data_reshaped[\u001b[39m2023\u001b[39m] \u001b[39m=\u001b[39m data_reshaped[\u001b[39m2022\u001b[39;49m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/super/Desktop/DATA_ENGINEERING/Project_git/FODE-23-22/dags/postgres/Exploration.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m data_reshaped\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/super/Desktop/DATA_ENGINEERING/Project_git/FODE-23-22/dags/postgres/Exploration.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Read cases_deaths data\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\super\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3804\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3805\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3806\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3807\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\super\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 2022"
     ]
    }
   ],
   "source": [
    "# HERE WE EXPLORE THE DATA AND CREATE A MERGED DATAFRAME\n",
    "import wbgapi as wb\n",
    "import pandas as pd\n",
    "\n",
    "# Get population data\n",
    "data = wb.data.DataFrame('SP.POP.TOTL', labels=True, time=range(2019, 2023))\n",
    "data[\"YR2023\"] = data[\"YR2022\"]\n",
    "print(data)\n",
    "# Reshape the population data\n",
    "data_reshaped = pd.melt(data, id_vars=['Country'], var_name='Year', value_name='Population')\n",
    "data_reshaped['Year'] = data_reshaped['Year'].apply(lambda year: int(year[2:]))\n",
    "\n",
    "data_reshaped = pd.melt(data, id_vars=['Country'], var_name='Year', value_name='Total Population')\n",
    "    \n",
    "#Manually add the population for 2023 and set it equal to the population of 2022\n",
    "data_reshaped[data_reshaped['Year'] == 2023] = data_reshaped[2022]\n",
    "data_reshaped\n",
    "# Read cases_deaths data\n",
    "df_cases_deaths = pd.read_csv('./cases_deaths.csv')\n",
    "\n",
    "# Extract year from Date_reported column and create a new column Year\n",
    "df_cases_deaths['Year'] = pd.DatetimeIndex(df_cases_deaths['Date_reported']).year\n",
    "\n",
    "\n",
    "# Merge the two dataframes based on Country and Year columns\n",
    "df_merged = pd.merge(df_cases_deaths, data_reshaped, how='left', on=['Country', 'Year'])\n",
    "\n",
    "df_merged.drop('Year', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create time dimensions DataFrame\n",
    "def create_time_dimension(start_year, end_year):\n",
    "    start_date = f\"{start_year}-01-01\"\n",
    "    end_date = f\"{end_year}-12-31\"\n",
    "    \n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    \n",
    "    data = {\n",
    "        'Date': date_range,\n",
    "        'Week': date_range.isocalendar().week,\n",
    "        'Month': date_range.month,\n",
    "        'Trimester': (date_range.month - 1) // 3 + 1,\n",
    "        'Semester': (date_range.month <= 6).astype(int) + 1,\n",
    "        'Year': date_range.year\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Create time dimension DataFrame for the years 2019 to 2024\n",
    "time_dimension_df = create_time_dimension(2019, 2024)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(time_dimension_df.head())\n",
    "In this version, pd.date_range is used to generate a daily frequency date range, and the resulting DataFrame is similar to the previous example. The isocalendar method is used to extract the ISO week and ISO year from the date range.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "\n",
    "kaggle.api.authenticate()\n",
    "\n",
    "kaggle.api.dataset_download_files('andradaolteanu/country-mapping-iso-continent-region', path='./..', unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username                            nicolacn\n",
       "key         f243b9b01cf0b0c0b7bd7d80d0aeab54\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# Create the directories if they don't exist\n",
    "os.makedirs('/opt/airflow/.kaggle', exist_ok=True)\n",
    "\n",
    "# Write the contents of the file\n",
    "with open('/opt/airflow/.kaggle/kaggle.json', 'w') as f:\n",
    "    f.write('{\"username\":\"nicolacn\",\"key\":\"f243b9b01cf0b0c0b7bd7d80d0aeab54\"}')\n",
    "df = pd.read_json('/opt/airflow/.kaggle/kaggle.json', typ='series')\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
